{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2_contingency, ttest_ind, shapiro\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.preprocessing import StandardScaler  # Ensure this is imported\n",
    "import os  # For folder creation\n",
    "import ast  # For safely evaluating string representations of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the final_dataset: 50073\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to your dataset\n",
    "filepath = \"D:/daten_masterarbeit/final_dataset_reg_full.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "print(f\"Number of observations in the final_dataset: {len(df)}\")\n",
    "\n",
    "#%% Data Preparation\n",
    "\n",
    "# List of variables to include in the analysis\n",
    "variables = [\n",
    "    'similarity_to_overall_average',\n",
    "    'similarity_to_industry_average',\n",
    "    'similarity_to_company_average',\n",
    "    'excess_ret_immediate',\n",
    "    'excess_ret_short_term',\n",
    "    'excess_ret_medium_term',\n",
    "    'excess_ret_long_term',\n",
    "    'epsfxq',\n",
    "    'epsfxq_next',\n",
    "    'length_participant_questions',  # Dependent Variable\n",
    "    'length_management_answers',    # Dependent Variable\n",
    "    'market_cap',                   # Control Variable\n",
    "    'rolling_beta',                 # Control Variable\n",
    "    'ceo_participates',             # Control Variable\n",
    "    'ceo_cfo_change',               # Control Variable\n",
    "    'word_length_presentation',     # Control Variable\n",
    "    'participant_question_topics',  # For Chi-Squared Test\n",
    "    'management_answer_topics',     # For Chi-Squared Test\n",
    "    'filtered_presentation_topics'  # For topic diversity\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations after dropping NaNs: 41500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure all variables exist in the DataFrame\n",
    "missing_vars = [var for var in variables if var not in df.columns]\n",
    "if missing_vars:\n",
    "    raise KeyError(f\"The following required columns are missing from the DataFrame: {missing_vars}\")\n",
    "\n",
    "# Create analysis DataFrame with the specified variables\n",
    "analysis_df = df[variables].dropna()\n",
    "\n",
    "# Display the number of observations after dropping NaNs\n",
    "print(f\"Number of observations after dropping NaNs: {len(analysis_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['similarity_to_overall_average', 'similarity_to_industry_average',\n",
       "       'similarity_to_company_average', 'excess_ret_immediate',\n",
       "       'excess_ret_short_term', 'excess_ret_medium_term',\n",
       "       'excess_ret_long_term', 'epsfxq', 'epsfxq_next',\n",
       "       'length_participant_questions', 'length_management_answers',\n",
       "       'market_cap', 'rolling_beta', 'ceo_participates', 'ceo_cfo_change',\n",
       "       'word_length_presentation', 'participant_question_topics',\n",
       "       'management_answer_topics', 'filtered_presentation_topics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analysis_df[['similarity_to_overall_average', 'similarity_to_industry_average', 'similarity_to_company_average','length_management_answers', 'length_participant_questions', 'filtered_presentation_topics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of filtered_presentation_topics (Lowest 20%): 149.00506024096384\n",
      "Average length of filtered_presentation_topics (Highest 20%): 130.65867469879518\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure that 'analysis_df' is your DataFrame\n",
    "# and that 'filtered_presentation_topics' contains string representations of lists.\n",
    "\n",
    "# Calculate the 20th and 80th quantiles once to avoid recalculating\n",
    "quantile_20 = analysis_df['similarity_to_industry_average'].quantile(0.2)\n",
    "quantile_80 = analysis_df['similarity_to_industry_average'].quantile(0.8)\n",
    "\n",
    "# Filter the lowest 20% of similarity_to_overall_average\n",
    "lowest_20_df = analysis_df[analysis_df['similarity_to_industry_average'] <= quantile_20]\n",
    "\n",
    "# Calculate the average length of filtered_presentation_topics vectors for lowest 20%\n",
    "lowest_20_avg_length = lowest_20_df['filtered_presentation_topics'].apply(\n",
    "    lambda x: len(ast.literal_eval(x)) if isinstance(x, str) else len(x)\n",
    ").mean()\n",
    "\n",
    "print(f\"Average length of filtered_presentation_topics (Lowest 20%): {lowest_20_avg_length}\")\n",
    "\n",
    "# Filter the highest 20% of similarity_to_overall_average\n",
    "highest_20_df = analysis_df[analysis_df['similarity_to_industry_average'] >= quantile_80]\n",
    "\n",
    "# Calculate the average length of filtered_presentation_topics vectors for highest 20%\n",
    "highest_20_avg_length = highest_20_df['filtered_presentation_topics'].apply(\n",
    "    lambda x: len(ast.literal_eval(x)) if isinstance(x, str) else len(x)\n",
    ").mean()\n",
    "\n",
    "print(f\"Average length of filtered_presentation_topics (Highest 20%): {highest_20_avg_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To_0</th>\n",
       "      <th>To_1</th>\n",
       "      <th>To_2</th>\n",
       "      <th>To_3</th>\n",
       "      <th>To_4</th>\n",
       "      <th>To_5</th>\n",
       "      <th>To_6</th>\n",
       "      <th>To_7</th>\n",
       "      <th>To_8</th>\n",
       "      <th>To_9</th>\n",
       "      <th>...</th>\n",
       "      <th>To_80</th>\n",
       "      <th>To_81</th>\n",
       "      <th>To_82</th>\n",
       "      <th>To_83</th>\n",
       "      <th>To_84</th>\n",
       "      <th>To_85</th>\n",
       "      <th>To_86</th>\n",
       "      <th>To_87</th>\n",
       "      <th>To_88</th>\n",
       "      <th>To_89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>From_0</th>\n",
       "      <td>7396</td>\n",
       "      <td>907</td>\n",
       "      <td>593</td>\n",
       "      <td>143</td>\n",
       "      <td>1067</td>\n",
       "      <td>2921</td>\n",
       "      <td>433</td>\n",
       "      <td>2279</td>\n",
       "      <td>1662</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From_1</th>\n",
       "      <td>4785</td>\n",
       "      <td>663</td>\n",
       "      <td>130</td>\n",
       "      <td>277</td>\n",
       "      <td>23</td>\n",
       "      <td>1536</td>\n",
       "      <td>2628</td>\n",
       "      <td>1079</td>\n",
       "      <td>214</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>637</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From_2</th>\n",
       "      <td>2395</td>\n",
       "      <td>3129</td>\n",
       "      <td>341</td>\n",
       "      <td>67</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>346</td>\n",
       "      <td>188</td>\n",
       "      <td>276</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1315</td>\n",
       "      <td>225</td>\n",
       "      <td>81</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>151</td>\n",
       "      <td>973</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From_3</th>\n",
       "      <td>556</td>\n",
       "      <td>657</td>\n",
       "      <td>265</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>1293</td>\n",
       "      <td>226</td>\n",
       "      <td>134</td>\n",
       "      <td>464</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>219</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From_4</th>\n",
       "      <td>577</td>\n",
       "      <td>2423</td>\n",
       "      <td>4656</td>\n",
       "      <td>908</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>197</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        To_0  To_1  To_2  To_3  To_4  To_5  To_6  To_7  To_8  To_9  ...  \\\n",
       "From_0  7396   907   593   143  1067  2921   433  2279  1662   138  ...   \n",
       "From_1  4785   663   130   277    23  1536  2628  1079   214    71  ...   \n",
       "From_2  2395  3129   341    67    19   135   346   188   276    43  ...   \n",
       "From_3   556   657   265    75    11  1293   226   134   464    16  ...   \n",
       "From_4   577  2423  4656   908    35    28    14    44   197   123  ...   \n",
       "\n",
       "        To_80  To_81  To_82  To_83  To_84  To_85  To_86  To_87  To_88  To_89  \n",
       "From_0    163     32     15     27      8     11     52    140      2     19  \n",
       "From_1    637     56      7     14     11      4     37    210      8      3  \n",
       "From_2   1315    225     81     46     12     16    151    973     12     19  \n",
       "From_3    219     13      9      1      1      1     30     89      2      4  \n",
       "From_4     38      4      5      3      2      2     36     22      3      9  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your transition matrix file\n",
    "file_path = r\"C:\\Users\\nikla\\OneDrive\\Dokumente\\winfoMaster\\Masterarbeit\\regression_results\\overall_transition_matrix.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "transition_matrix_df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Display the DataFrame\n",
    "transition_matrix_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized transition matrix saved as 'normalized_transition_matrix.csv'.\n",
      "Top frequent transitions with probabilities:\n",
      "    From Topic  To Topic  Frequency  Probability\n",
      "0           33        33      18877     0.443322\n",
      "5           69        69      22414     0.352200\n",
      "6           87        87      22464     0.344856\n",
      "1            5         4      18886     0.324323\n",
      "10          72        72      26038     0.297631\n",
      "19          23        23     135337     0.285963\n",
      "14          14        12      29782     0.254084\n",
      "12          40        40      27033     0.251482\n",
      "4           86        86      22185     0.232621\n",
      "2           21        21      19343     0.226236\n",
      "7           25        25      22911     0.219761\n",
      "9           11        11      25985     0.205311\n",
      "13          14        14      29161     0.202912\n",
      "18          19        19      66203     0.184751\n",
      "8           68        68      24025     0.168747\n",
      "3           70        70      19405     0.153917\n",
      "15          78        78      35976     0.148879\n",
      "16          22        22      42493     0.131142\n",
      "17          80        80      45425     0.126202\n",
      "11          20        20      27012     0.117494\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `transition_matrix_df` is the loaded DataFrame\n",
    "# Convert DataFrame to a numpy array for easier processing\n",
    "transition_matrix = transition_matrix_df.to_numpy()\n",
    "\n",
    "# Normalize the rows to get probabilities\n",
    "row_sums = transition_matrix.sum(axis=1, keepdims=True)\n",
    "probability_matrix = np.divide(\n",
    "    transition_matrix,\n",
    "    row_sums,\n",
    "    where=row_sums != 0  # Avoid division by zero\n",
    ")\n",
    "\n",
    "# Convert back to a DataFrame for better exploration\n",
    "probability_matrix_df = pd.DataFrame(\n",
    "    probability_matrix,\n",
    "    index=transition_matrix_df.index,\n",
    "    columns=transition_matrix_df.columns\n",
    ")\n",
    "\n",
    "# Save the normalized matrix to a CSV file for further exploration (optional)\n",
    "probability_matrix_df.to_csv(\"normalized_transition_matrix.csv\")\n",
    "print(\"Normalized transition matrix saved as 'normalized_transition_matrix.csv'.\")\n",
    "\n",
    "# Find the top N most frequent transitions\n",
    "N = 20  # Adjust N to show more or fewer transitions\n",
    "flat_indices = np.argsort(transition_matrix, axis=None)[-N:]  # Indices of the top N values in flattened array\n",
    "top_values = transition_matrix.flatten()[flat_indices]  # Corresponding values of these indices\n",
    "rows, cols = np.unravel_index(flat_indices, transition_matrix.shape)  # Convert to 2D indices\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "frequent_transitions = pd.DataFrame({\n",
    "    \"From Topic\": rows,\n",
    "    \"To Topic\": cols,\n",
    "    \"Frequency\": top_values\n",
    "}).sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "# Display the top transitions\n",
    "#print(\"Top frequent transitions:\")\n",
    "#print(frequent_transitions)\n",
    "\n",
    "# To view the corresponding probabilities of the top transitions:\n",
    "frequent_transitions[\"Probability\"] = probability_matrix[rows, cols]\n",
    "#sort by Probability\n",
    "frequent_transitions = frequent_transitions.sort_values(by=\"Probability\", ascending=False)\n",
    "print(\"Top frequent transitions with probabilities:\")\n",
    "print(frequent_transitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"siccd\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby(\"siccd\")[\"permco\"].nunique()\n",
    "industries_with_10_permcos = df_grouped[df_grouped >= 5]\n",
    "count_of_industries = len(industries_with_10_permcos)\n",
    "print(count_of_industries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31948\\88183917.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"siccd\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nikla\\miniconda3\\envs\\bert_ma\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'freq'"
     ]
    }
   ],
   "source": [
    "df[\"siccd\"].freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\nikla\\AppData\\Local\\Temp\\ipykernel_31948\\1070434396.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  acc_daten = pd.read_csv(\"D:\\daten_masterarbeit\\CRSP_monthly_Compustat_quarterly_merged.csv\", nrows=100000)\n"
     ]
    }
   ],
   "source": [
    "#read this to pandas\n",
    "#\"D:\\daten_masterarbeit\\CRSP_monthly_Compustat_quarterly_merged.csv\" \n",
    "acc_daten = pd.read_csv(\"D:\\daten_masterarbeit\\CRSP_monthly_Compustat_quarterly_merged.csv\", nrows=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['permno', 'date', 'exchcd', 'siccd', 'ncusip', 'ticker', 'comnam',\n",
       "       'permco', 'prc', 'vol', 'ret', 'shrout', 'cfacpr', 'cfacshr',\n",
       "       'month_id', 'year', 'gvkey', 'month_id_datadate', 'datadate', 'fyearq',\n",
       "       'fqtr', 'fyr', 'conm', 'datacqtr', 'datafqtr', 'rdq', 'atq', 'ceqq',\n",
       "       'dlcq', 'dlttq', 'epsfiq', 'epsfxq', 'epspiq', 'epspxq', 'ibq', 'ltq',\n",
       "       'niq', 'oiadpq', 'xidoq', 'xiq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_daten.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epsfxq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>-1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       epsfxq\n",
       "0         NaN\n",
       "1         NaN\n",
       "2        0.59\n",
       "3         NaN\n",
       "4         NaN\n",
       "...       ...\n",
       "99995   -1.22\n",
       "99996     NaN\n",
       "99997     NaN\n",
       "99998   -1.48\n",
       "99999    0.00\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_daten[[\"epsfxq\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
