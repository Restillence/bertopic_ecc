{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2_contingency, ttest_ind, shapiro\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.preprocessing import StandardScaler  # Ensure this is imported\n",
    "import os  # For folder creation\n",
    "import ast  # For safely evaluating string representations of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the final_dataset: 50073\n",
      "Number of observations after dropping NaNs: 41500\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to your dataset\n",
    "filepath = \"D:/daten_masterarbeit/final_dataset_reg_full.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "print(f\"Number of observations in the final_dataset: {len(df)}\")\n",
    "\n",
    "#%% Data Preparation\n",
    "\n",
    "# List of variables to include in the analysis\n",
    "variables = [\n",
    "    'similarity_to_overall_average',\n",
    "    'similarity_to_industry_average',\n",
    "    'similarity_to_company_average',\n",
    "    'excess_ret_immediate',\n",
    "    'excess_ret_short_term',\n",
    "    'excess_ret_medium_term',\n",
    "    'excess_ret_long_term',\n",
    "    'epsfxq',\n",
    "    'epsfxq_next',\n",
    "    'length_participant_questions',  # Dependent Variable\n",
    "    'length_management_answers',    # Dependent Variable\n",
    "    'market_cap',                   # Control Variable\n",
    "    'rolling_beta',                 # Control Variable\n",
    "    'ceo_participates',             # Control Variable\n",
    "    'ceo_cfo_change',               # Control Variable\n",
    "    'word_length_presentation',     # Control Variable\n",
    "    'participant_question_topics',  # For Chi-Squared Test\n",
    "    'management_answer_topics',     # For Chi-Squared Test\n",
    "    'filtered_presentation_topics'  # For topic diversity\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations after dropping NaNs: 41500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure all variables exist in the DataFrame\n",
    "missing_vars = [var for var in variables if var not in df.columns]\n",
    "if missing_vars:\n",
    "    raise KeyError(f\"The following required columns are missing from the DataFrame: {missing_vars}\")\n",
    "\n",
    "# Create analysis DataFrame with the specified variables\n",
    "analysis_df = df[variables].dropna()\n",
    "\n",
    "# Display the number of observations after dropping NaNs\n",
    "print(f\"Number of observations after dropping NaNs: {len(analysis_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['similarity_to_overall_average', 'similarity_to_industry_average',\n",
       "       'similarity_to_company_average', 'excess_ret_immediate',\n",
       "       'excess_ret_short_term', 'excess_ret_medium_term',\n",
       "       'excess_ret_long_term', 'epsfxq', 'epsfxq_next',\n",
       "       'length_participant_questions', 'length_management_answers',\n",
       "       'market_cap', 'rolling_beta', 'ceo_participates', 'ceo_cfo_change',\n",
       "       'word_length_presentation', 'participant_question_topics',\n",
       "       'management_answer_topics', 'filtered_presentation_topics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analysis_df[['similarity_to_overall_average', 'similarity_to_industry_average', 'similarity_to_company_average','length_management_answers', 'length_participant_questions', 'filtered_presentation_topics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of filtered_presentation_topics (Lowest 20%): 149.00506024096384\n",
      "Average length of filtered_presentation_topics (Highest 20%): 130.65867469879518\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure that 'analysis_df' is your DataFrame\n",
    "# and that 'filtered_presentation_topics' contains string representations of lists.\n",
    "\n",
    "# Calculate the 20th and 80th quantiles once to avoid recalculating\n",
    "quantile_20 = analysis_df['similarity_to_industry_average'].quantile(0.2)\n",
    "quantile_80 = analysis_df['similarity_to_industry_average'].quantile(0.8)\n",
    "\n",
    "# Filter the lowest 20% of similarity_to_overall_average\n",
    "lowest_20_df = analysis_df[analysis_df['similarity_to_industry_average'] <= quantile_20]\n",
    "\n",
    "# Calculate the average length of filtered_presentation_topics vectors for lowest 20%\n",
    "lowest_20_avg_length = lowest_20_df['filtered_presentation_topics'].apply(\n",
    "    lambda x: len(ast.literal_eval(x)) if isinstance(x, str) else len(x)\n",
    ").mean()\n",
    "\n",
    "print(f\"Average length of filtered_presentation_topics (Lowest 20%): {lowest_20_avg_length}\")\n",
    "\n",
    "# Filter the highest 20% of similarity_to_overall_average\n",
    "highest_20_df = analysis_df[analysis_df['similarity_to_industry_average'] >= quantile_80]\n",
    "\n",
    "# Calculate the average length of filtered_presentation_topics vectors for highest 20%\n",
    "highest_20_avg_length = highest_20_df['filtered_presentation_topics'].apply(\n",
    "    lambda x: len(ast.literal_eval(x)) if isinstance(x, str) else len(x)\n",
    ").mean()\n",
    "\n",
    "print(f\"Average length of filtered_presentation_topics (Highest 20%): {highest_20_avg_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
