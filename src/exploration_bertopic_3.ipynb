{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bertopic import BERTopic\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 11:48:19,031 - BERTopic - WARNING: You are loading a BERTopic model without explicitly defining an embedding model. If you want to also load in an embedding model, make sure to use `BERTopic.load(my_model, embedding_model=my_embedding_model)`.\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from config.json\n",
    "config_file_path = r'C:\\Users\\nikla\\OneDrive\\Dokumente\\winfoMaster\\Masterarbeit\\bertopic_ecc\\config.json'\n",
    "with open(config_file_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Get the correct model path from the config\n",
    "model_load_path = config[\"model_load_path\"]\n",
    "\n",
    "# Load the embedding model and ensure it's loaded onto the CPU\n",
    "embedding_model = SentenceTransformer(config[\"embedding_model_choice\"], device=\"cpu\")\n",
    "\n",
    "# Manually load the model and ensure all GPU-based tensors are mapped to CPU\n",
    "def custom_torch_load(path):\n",
    "    return torch.load(path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the BERTopic model from the local path\n",
    "# Catching any model-level components that need to be loaded on the CPU\n",
    "topic_model = BERTopic.load(model_load_path)\n",
    "\n",
    "# Manually adjust any GPU-related components within the model if necessary (for example, handling specific components that still have GPU data)\n",
    "# Ensure all parts are mapped to the CPU\n",
    "topic_model.embedding_model = embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correct model path from the updated config\n",
    "model_load_path_with_data = config[\"model_load_path_with_data\"]\n",
    "\n",
    "# Load the model from the local path\n",
    "topic_model = BERTopic.load(model_load_path_with_data)\n",
    "\n",
    "# Access the original documents (untransformed)\n",
    "original_documents = topic_model.original_documents_\n",
    "\n",
    "# Access the transformed topics and probabilities\n",
    "transformed_topics = topic_model.topics_\n",
    "transformed_probabilities = topic_model.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access original documents\n",
    "documents = topic_model.original_documents_\n",
    "\n",
    "# Access topics assigned to each document\n",
    "topics = topic_model.topics_\n",
    "\n",
    "# Access topic probabilities (if available)\n",
    "probabilities = topic_model.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good day, ladies and gentlemen, and welcome to the Neuronetics Fourth Quarter and Full Year 2018 Earnings Conference Call. (Operator Instructions) As a reminder, this conference call is being recorded', \"I would now like to introduce your host for today's conference, Mr. Mark Klausner from Westwicke. Sir, you may begin\", \"Thank you, operator. Good morning, and thank you for joining us for Neuronetics' Fourth Quarter and Full Year 2018 Conference Call. A replay of this call will be available on our website for 30 days. Joining me on today's call are: Neuronetics' Chief Executive Officer, Chris Thatcher; and its Chief Financial Officer, Peter Donato\", \"Before we begin, I would like to caution listeners that certain information discussed by management during this conference call will include forward-looking statements covered under the safe harbor provisions of the Private Securities Litigation Reform Act of 1995, including statements related to our business strategy, financial and revenue guidance and other operational items and metrics. Actual results could differ materially from those stated or implied by these forward-looking statements due to risks and uncertainties associated with the company's business. For a discussion of risks and uncertainties associated with Neuronetics' business, I encourage you to review the company's filings with the Securities and Exchange Commission, including the company's Annual Report on Form 10-K that will be filed today. The company disclaims any obligation to update any forward-looking statements made during the course of this call, except as required by law\", \"During the call, we'll also discuss certain financial information on a non-GAAP basis, including EBITDA. Management believes that non-GAAP financial measures, taken in conjunction with U.S. GAAP financial measures, provide useful information for both management and investors by excluding certain noncash and other expenses that are not indicative of our core operating results. Management uses non-GAAP measures to compare our performance relative to forecasts and strategic plans to benchmark our performance externally against competitors and for certain compensation decisions. Reconciliations between U.S. GAAP and non-GAAP results are presented in tables accompanying our press release, which can be viewed on our website\"]\n"
     ]
    }
   ],
   "source": [
    "#print first 5 documents\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BERTopic' object has no attribute '_outliers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_topics, new_probs \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnr_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikla\\miniconda3\\envs\\bert_ma\\Lib\\site-packages\\bertopic\\_bertopic.py:2053\u001b[0m, in \u001b[0;36mBERTopic.reduce_topics\u001b[1;34m(self, docs, nr_topics, images)\u001b[0m\n\u001b[0;32m   2050\u001b[0m documents \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopics_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m: images, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs))})\n\u001b[0;32m   2052\u001b[0m \u001b[38;5;66;03m# Reduce number of topics\u001b[39;00m\n\u001b[1;32m-> 2053\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merged_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_representative_docs(documents)\n",
      "File \u001b[1;32mc:\\Users\\nikla\\miniconda3\\envs\\bert_ma\\Lib\\site-packages\\bertopic\\_bertopic.py:4105\u001b[0m, in \u001b[0;36mBERTopic._reduce_topics\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   4104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics \u001b[38;5;241m<\u001b[39m initial_nr_topics:\n\u001b[1;32m-> 4105\u001b[0m         documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce_to_n_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   4107\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_reduce_topics(documents)\n",
      "File \u001b[1;32mc:\\Users\\nikla\\miniconda3\\envs\\bert_ma\\Lib\\site-packages\\bertopic\\_bertopic.py:4127\u001b[0m, in \u001b[0;36mBERTopic._reduce_to_n_topics\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m   4125\u001b[0m \u001b[38;5;66;03m# Create topic distance matrix\u001b[39;00m\n\u001b[0;32m   4126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_embeddings_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4127\u001b[0m     topic_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_embeddings_[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outliers\u001b[49m:, ]\n\u001b[0;32m   4128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4129\u001b[0m     topic_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_tf_idf_[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outliers:, ]\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BERTopic' object has no attribute '_outliers'"
     ]
    }
   ],
   "source": [
    "new_topics, new_probs = topic_model.reduce_topics(nr_topics=20,docs=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring Basic Information about the Model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BERTopic' object has no attribute 'topic_labels_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Call this function\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mexplore_basic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m, in \u001b[0;36mexplore_basic_info\u001b[1;34m(topic_model)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExploring Basic Information about the Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get the number of topics\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Topics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_topics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Get topic frequency (number of documents per topic)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikla\\miniconda3\\envs\\bert_ma\\Lib\\site-packages\\bertopic\\_bertopic.py:1517\u001b[0m, in \u001b[0;36mBERTopic.get_topic_info\u001b[1;34m(self, topic)\u001b[0m\n\u001b[0;32m   1514\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1516\u001b[0m info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_sizes_\u001b[38;5;241m.\u001b[39mitems(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1517\u001b[0m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mTopic\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopic_labels_\u001b[49m)\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;66;03m# Custom label\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_labels_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BERTopic' object has no attribute 'topic_labels_'"
     ]
    }
   ],
   "source": [
    "def explore_basic_info(topic_model):\n",
    "    \"\"\"\n",
    "    Explore the basic information about the BERTopic model.\n",
    "    \"\"\"\n",
    "    print(\"Exploring Basic Information about the Model...\")\n",
    "    # Get the number of topics\n",
    "    num_topics = len(topic_model.get_topic_info())\n",
    "    print(f\"Number of Topics: {num_topics}\")\n",
    "    \n",
    "    # Get topic frequency (number of documents per topic)\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    print(\"Top 5 Topics by Frequency:\")\n",
    "    print(topic_info.head(5))\n",
    "    \n",
    "    # Get top words for a specific topic (example: topic 0)\n",
    "    example_topic = 0\n",
    "    top_words = topic_model.get_topic(example_topic)\n",
    "    print(f\"Top words for Topic {example_topic}:\")\n",
    "    for word, score in top_words:\n",
    "        print(f\"  - {word}: {score}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Call this function\n",
    "explore_basic_info(topic_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_and_explore(topic_model, nr_topics):\n",
    "    \"\"\"\n",
    "    Reduce the number of topics in the model and explore the new model.\n",
    "    \"\"\"\n",
    "    print(f\"Reducing number of topics to {nr_topics}...\")\n",
    "    reduced_model = topic_model.reduce_topics(topic_model.original_documents_, nr_topics=nr_topics)\n",
    "    \n",
    "    # Print reduced model info\n",
    "    explore_basic_info(reduced_model)\n",
    "    \n",
    "    return reduced_model\n",
    "\n",
    "# Example: Reduce topics to 30\n",
    "reduced_model = reduce_and_explore(topic_model, nr_topics=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Topic Distribution...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BERTopic' object has no attribute 'topic_labels_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize topic distribution of the reduced model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mvisualize_topics_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mvisualize_topics_distribution\u001b[1;34m(topic_model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mVisualize the distribution of topics.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing Topic Distribution...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m topic_info \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m      8\u001b[0m ax\u001b[38;5;241m.\u001b[39mbar(topic_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m'\u001b[39m], topic_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\nikla\\miniconda3\\envs\\bert_ma\\Lib\\site-packages\\bertopic\\_bertopic.py:1517\u001b[0m, in \u001b[0;36mBERTopic.get_topic_info\u001b[1;34m(self, topic)\u001b[0m\n\u001b[0;32m   1514\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1516\u001b[0m info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_sizes_\u001b[38;5;241m.\u001b[39mitems(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1517\u001b[0m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mTopic\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopic_labels_\u001b[49m)\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;66;03m# Custom label\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_labels_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BERTopic' object has no attribute 'topic_labels_'"
     ]
    }
   ],
   "source": [
    "def visualize_topics_distribution(topic_model):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of topics.\n",
    "    \"\"\"\n",
    "    print(\"Visualizing Topic Distribution...\")\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(topic_info['Topic'], topic_info['Count'])\n",
    "    ax.set_xlabel('Topic')\n",
    "    ax.set_ylabel('Number of Documents')\n",
    "    ax.set_title('Topic Distribution')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize topic distribution of the reduced model\n",
    "visualize_topics_distribution(topic_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic_diversity(topic_model):\n",
    "    \"\"\"\n",
    "    Explore the diversity of topics.\n",
    "    \"\"\"\n",
    "    print(\"Exploring Topic Diversity...\")\n",
    "    diversity_scores = topic_model.topic_diversity(topic_model.topics_)\n",
    "    print(f\"Average Topic Diversity: {sum(diversity_scores)/len(diversity_scores)}\")\n",
    "    \n",
    "    # Print diversity of the first few topics\n",
    "    for i in range(5):\n",
    "        print(f\"Topic {i} Diversity: {diversity_scores[i]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Call the function to explore topic diversity\n",
    "explore_topic_diversity(reduced_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reducing to a different number of topics\n",
    "nr_topics = 50\n",
    "reduced_model_50 = reduce_and_explore(topic_model, nr_topics=nr_topics)\n",
    "\n",
    "# Visualize topic distribution after further reduction\n",
    "visualize_topics_distribution(reduced_model_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reduced model\n",
    "reduced_model.save(\"path_to_save_reduced_model\")\n",
    "print(\"Reduced model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
